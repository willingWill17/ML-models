{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu7AHPsivM0s"
   },
   "source": [
    "**Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T14:06:16.610492Z",
     "iopub.status.busy": "2025-04-19T14:06:16.610195Z",
     "iopub.status.idle": "2025-04-19T14:06:16.657408Z",
     "shell.execute_reply": "2025-04-19T14:06:16.656463Z",
     "shell.execute_reply.started": "2025-04-19T14:06:16.610470Z"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "error",
     "timestamp": 1746892325198,
     "user": {
      "displayName": "Real Hoàng Quân",
      "userId": "16831795249381507015"
     },
     "user_tz": -420
    },
    "id": "pAt8iZInvM0u",
    "outputId": "e948099c-9860-4489-e06d-f54fcc1c19e5",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../kaggle/input/d/lainguyn123/student-performance-factors/StudentPerformanceFactors.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d9b05aa8947b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Read dataset from csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../kaggle/input/d/lainguyn123/student-performance-factors/StudentPerformanceFactors.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Drop any missing-value row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../kaggle/input/d/lainguyn123/student-performance-factors/StudentPerformanceFactors.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Read dataset from csv file\n",
    "df = pd.read_csv('../kaggle/input/d/lainguyn123/student-performance-factors/StudentPerformanceFactors.csv')\n",
    "\n",
    "# Drop any missing-value row\n",
    "df = df.dropna(how=\"all\")\n",
    "\n",
    "# Make dataset\n",
    "X = df.drop([\"Exam_Score\"], axis=1)\n",
    "y = df['Exam_Score']\n",
    "\n",
    "# Data Scaling and Non-numerical Value Processing\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Build train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFsW1bwNvM0w"
   },
   "source": [
    "**Trying multiple argument degrees for Polynomial Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T14:06:16.659640Z",
     "iopub.status.busy": "2025-04-19T14:06:16.658834Z",
     "iopub.status.idle": "2025-04-19T14:07:33.628657Z",
     "shell.execute_reply": "2025-04-19T14:07:33.627759Z",
     "shell.execute_reply.started": "2025-04-19T14:06:16.659611Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "error",
     "timestamp": 1746892316929,
     "user": {
      "displayName": "Real Hoàng Quân",
      "userId": "16831795249381507015"
     },
     "user_tz": -420
    },
    "id": "pdSYPcWrvM0w",
    "outputId": "ef2c4c4e-c45d-41c4-ffc6-1b659439af6e",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3bbfec21a6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m preprocessor = ColumnTransformer(\n\u001b[1;32m      7\u001b[0m     transformers=[\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categorical_cols' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------Degree 1------------------------------------------------------------\n",
    "pipeline_1 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=1, include_bias=True)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "pipeline_1.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred_1 = pipeline_1.predict(X_train)\n",
    "y_test_pred_1 = pipeline_1.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse_1 = mean_squared_error(y_train, y_train_pred_1)\n",
    "test_mse_1 = mean_squared_error(y_test, y_test_pred_1)\n",
    "train_r2_1 = r2_score(y_train, y_train_pred_1)\n",
    "test_r2_1 = r2_score(y_test, y_test_pred_1)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE with degree 1:\", train_mse_1)\n",
    "print(\"Test MSE with degree 1:\", test_mse_1)\n",
    "print(\"Training R² with degree 1:\", train_r2_1)\n",
    "print(\"Test R² with degree 1:\", test_r2_1)\n",
    "\n",
    "# ------------------------------------------------------Degree 2------------------------------------------------------------\n",
    "pipeline_2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=True)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "pipeline_2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred_2 = pipeline_2.predict(X_train)\n",
    "y_test_pred_2 = pipeline_2.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse_2 = mean_squared_error(y_train, y_train_pred_2)\n",
    "test_mse_2 = mean_squared_error(y_test, y_test_pred_2)\n",
    "train_r2_2 = r2_score(y_train, y_train_pred_2)\n",
    "test_r2_2 = r2_score(y_test, y_test_pred_2)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE with degree 2:\", train_mse_2)\n",
    "print(\"Test MSE with degree 2:\", test_mse_2)\n",
    "print(\"Training R² with degree 2:\", train_r2_2)\n",
    "print(\"Test R² with degree 2:\", test_r2_2)\n",
    "\n",
    "# ------------------------------------------------------Degree 3------------------------------------------------------------\n",
    "pipeline_3 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=True)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "pipeline_3.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred_3 = pipeline_3.predict(X_train)\n",
    "y_test_pred_3 = pipeline_3.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse_3 = mean_squared_error(y_train, y_train_pred_3)\n",
    "test_mse_3 = mean_squared_error(y_test, y_test_pred_3)\n",
    "train_r2_3 = r2_score(y_train, y_train_pred_3)\n",
    "test_r2_3 = r2_score(y_test, y_test_pred_3)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE with degree 3:\", train_mse_3)\n",
    "print(\"Test MSE with degree 3:\", test_mse_3)\n",
    "print(\"Training R² with degree 3:\", train_r2_3)\n",
    "print(\"Test R² with degree 3:\", test_r2_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8st1U0SnvM0x"
   },
   "source": [
    "**Build model from exisiting libraries and frameworks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:07:33.630303Z",
     "iopub.status.busy": "2025-04-19T14:07:33.629786Z",
     "iopub.status.idle": "2025-04-19T14:07:34.679071Z",
     "shell.execute_reply": "2025-04-19T14:07:34.678023Z",
     "shell.execute_reply.started": "2025-04-19T14:07:33.630271Z"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "aborted",
     "timestamp": 1746892275417,
     "user": {
      "displayName": "Real Hoàng Quân",
      "userId": "16831795249381507015"
     },
     "user_tz": -420
    },
    "id": "1feZZUbRvM0x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=True)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Training R²:\", train_r2)\n",
    "print(\"Test R²:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T14:07:34.680508Z",
     "iopub.status.busy": "2025-04-19T14:07:34.680104Z",
     "iopub.status.idle": "2025-04-19T14:07:34.793917Z",
     "shell.execute_reply": "2025-04-19T14:07:34.792982Z",
     "shell.execute_reply.started": "2025-04-19T14:07:34.680467Z"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "aborted",
     "timestamp": 1746892275418,
     "user": {
      "displayName": "Real Hoàng Quân",
      "userId": "16831795249381507015"
     },
     "user_tz": -420
    },
    "id": "cjFEMSEovM0x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OneHotEncoderCustom:\n",
    "    def fit(self, X):\n",
    "        self.categories_ = {}\n",
    "        for col in X.columns:\n",
    "            # Drop NaN and convert all to string to prevent mixed types\n",
    "            values = X[col].dropna().astype(str)\n",
    "            self.categories_[col] = sorted(set(values))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_enc = []\n",
    "        for _, row in X.iterrows():\n",
    "            encoded_row = []\n",
    "            for col in X.columns:\n",
    "                row_val = str(row[col]) if pd.notnull(row[col]) else None\n",
    "                for val in self.categories_[col]:\n",
    "                    encoded_row.append(1 if row_val == val else 0)\n",
    "            X_enc.append(encoded_row)\n",
    "        return np.array(X_enc)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "class StandardScalerCustom:\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean().values\n",
    "        self.scale_ = X.std(ddof=0).values\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ((X - self.mean_) / self.scale_).values\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "# === Custom ColumnTransformer ===\n",
    "\n",
    "class ColumnTransformerCustom:\n",
    "    def __init__(self, transformers):\n",
    "        self.transformers = transformers\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.fitted_transformers_ = []\n",
    "        for name, transformer, columns in self.transformers:\n",
    "            t = transformer.fit(X[columns])\n",
    "            self.fitted_transformers_.append((name, t, columns))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        transformed_parts = []\n",
    "        for name, transformer, columns in self.fitted_transformers_:\n",
    "            transformed_parts.append(transformer.transform(X[columns]))\n",
    "        return np.hstack(transformed_parts)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "# === Custom Linear Regression ===\n",
    "\n",
    "class PolynomialFeaturesCustom:\n",
    "    def __init__(self, degree=2, include_bias=True):\n",
    "        self.degree = degree\n",
    "        self.include_bias = include_bias\n",
    "\n",
    "    def fit(self, X):\n",
    "        from itertools import combinations_with_replacement\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.combos = [()] if self.include_bias else []\n",
    "        for d in range(1, self.degree + 1):\n",
    "            self.combos.extend(combinations_with_replacement(range(self.n_features_in_), d))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X_new = np.empty((n_samples, len(self.combos)), dtype=X.dtype)\n",
    "        for i, comb in enumerate(self.combos):\n",
    "            X_new[:, i] = np.prod(X[:, comb], axis=1) if comb else np.ones(n_samples)\n",
    "        return X_new\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "class LinearRegressionCustom:\n",
    "    def fit(self, X, y):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        self.theta_ = np.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        return X_b @ self.theta_\n",
    "\n",
    "# === Custom Metrics ===\n",
    "\n",
    "def mean_squared_error_custom(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2_score_custom(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "# === Custom Pipeline ===\n",
    "\n",
    "class PipelineCustom:\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for name, step in self.steps[:-1]:\n",
    "            X = step.fit_transform(X)\n",
    "        self.steps[-1][1].fit(X, y)\n",
    "        self.X_transformed_ = X\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        for name, step in self.steps[:-1]:\n",
    "            X = step.transform(X)\n",
    "        return self.steps[-1][1].predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "execution": {
     "iopub.execute_input": "2025-04-19T14:07:34.795812Z",
     "iopub.status.busy": "2025-04-19T14:07:34.795505Z",
     "iopub.status.idle": "2025-04-19T14:07:36.911313Z",
     "shell.execute_reply": "2025-04-19T14:07:36.910449Z",
     "shell.execute_reply.started": "2025-04-19T14:07:34.795779Z"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "error",
     "timestamp": 1746892308615,
     "user": {
      "displayName": "Real Hoàng Quân",
      "userId": "16831795249381507015"
     },
     "user_tz": -420
    },
    "id": "fVzppH7yvM0y",
    "outputId": "4aa27512-4093-4eab-a842-e199bee8f629",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformerCustom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fab6b55f718>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m preprocessor = ColumnTransformerCustom([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoderCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScalerCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ColumnTransformerCustom' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformerCustom([\n",
    "    ('cat', OneHotEncoderCustom(), categorical_cols),\n",
    "    ('num', StandardScalerCustom(), numeric_cols)\n",
    "])\n",
    "\n",
    "pipeline = PipelineCustom([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', PolynomialFeaturesCustom(degree=2)),\n",
    "    ('regressor', LinearRegressionCustom())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"Training MSE:\", mean_squared_error_custom(y_train.values, y_train_pred))\n",
    "print(\"Test MSE:\", mean_squared_error_custom(y_test.values, y_test_pred))\n",
    "print(\"Training R²:\", r2_score_custom(y_train.values, y_train_pred))\n",
    "print(\"Test R²:\", r2_score_custom(y_test.values, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5630996,
     "sourceId": 10020238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
